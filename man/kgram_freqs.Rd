% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fast_kgram_freqs.R, R/get_kgram_freqs_doc.R,
%   R/kgram_freqs.R
\name{fast_kgram_freqs}
\alias{fast_kgram_freqs}
\alias{kgram_freqs}
\title{k-gram frequency tables}
\usage{
fast_kgram_freqs(corpus, N, dict, erase = "", tolower = TRUE, EOS = "")

kgram_freqs(corpus, N, dict, .preprocess = identity, EOS = "")
}
\arguments{
\item{N}{a length one integer. The maximum order of k-grams
for which frequencies are sought.}

\item{dict}{either a character vector, or a length one integer/numeric.
The language model fixed dictionary (see details), sorted by word frequency.
If numeric, the dictionary is obtained from the training corpus using
the \code{dict} most frequent words.}

\item{erase}{a length one character vector. Regular expression matching
parts  of text to be erased from input. The default removes anything not
alphanumeric, white space, apostrophes or punctuation characters
(i.e. ".?!:;").}

\item{EOS}{a length one character vector listing all (single character)
end-of-sentence tokens.}

\item{.preprocess}{a function to apply before k-gram
tokenization.}

\item{text}{a character vector. The training corpus from which to extract
k-gram frequencies.}

\item{lower_case}{a length one logical vector. If TRUE, puts everything to
lower case.}
}
\value{
A \code{sbo_kgram_freqs} object, containing the k-gram
frequency tables for k = 1, 2, ..., N.
}
\description{
Get k-gram frequency tables from a training corpus.
}
\details{
These functions extract all k-gram frequency tables from a text
corpus up to a specified k-gram order N. These are
the building blocks to train any N-gram model.

The optimized version \code{kgram_freqs_fast(erase = x, lower_case = y)}
is equivalent to
\code{kgram_freqs(.preprocess = preprocess(erase = x, lower_case = y))},
but more efficient (both from the speed and memory point of view).

\code{kgram_freqs} and \code{kgram_freqs_fast} employ a fixed
(user specified) dictionary; any out-of-vocabulary word gets effectively
replaced by an "unknown word" token.

The return value is a "\code{sbo_kgram_freqs}" object, i.e. a list of N tibbles,
storing frequency counts for each k-gram observed in the training corpus, for
k = 1, 2, ..., N. In these tables, words are represented by
integer numbers corresponding to their position in the
reference dictionary. The special codes \code{0},
\code{length(dictionary)+1} and \code{length(dictionary)+2}
correspond to the "Begin-Of-Sentence", "End-Of-Sentence"
and "Unknown word" tokens, respectively.

Furthermore, the returned objected has the following attributes:
\itemize{
\item \code{N}: The highest order of N-grams.
\item \code{dict}: The reference dictionary, sorted by word frequency.
\item \code{.preprocess}: The function used for text preprocessing.
\item \code{EOS}: A length one character vector listing all (single character)
end-of-sentence tokens employed in k-gram tokenization.
}

The \code{.preprocess} argument of \code{kgram_freqs} allows the user to
employ a custom corpus preprocessing function.

The algorithm for k-gram tokenization considers anything separated by
(any number of) white spaces (i.e. " ") as a single word. Sentences are split
according to end-of-sentence (single character) tokens, as specified
by the \code{EOS} argument. Additionally text belonging to different entries of
the preprocessed input vector which are understood to belong to different
sentences.

\strong{\emph{Nota Bene}}: It is useful to keep in mind that the function
passed through the  \code{.preprocess} argument also captures its enclosing
environment, which is by default the environment in which the former
was defined.
If, for instance, \code{.preprocess} was defined in the global environment,
and the latter binds heavy objects, the resulting \code{sbo_kgram_freqs} will
contain bindings to the same objects. If \code{sbo_kgram_freqs} is stored out of
memory and recalled in another R session, these objects will also be reloaded
in memory.
For this reason, for non interactive use, it is advisable to avoid using
preprocessing functions defined in the global environment
(for instance, \code{base::identity} is preferred to \code{function(x) x}).
}
\examples{
\donttest{
# Obtain k-gram frequency table from corpus
## Get k-gram frequencies, up to k = N = 3.
freqs <- kgram_freqs_fast(twitter_train, N = 3, dict = twitter_dict)
## Print result
freqs
}
\donttest{
# Obtain k-gram frequency table from corpus
## Get k-gram frequencies, up to k = N = 3.
freqs <- kgram_freqs(twitter_train, N = 3, dict = twitter_dict)
## Print result
freqs
}
}
\seealso{
\code{\link[sbo]{get_word_freqs}}
}
\author{
Valerio Gherardi
}
