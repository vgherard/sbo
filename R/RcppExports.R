# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

get_pc_ptr <- function(object) {
    .Call(`_sbo_get_pc_ptr`, object)
}

get_word_freqsC <- function(text) {
    .Call(`_sbo_get_word_freqsC`, text)
}

kgram_freqs_cpp <- function(sentences, N, dict) {
    .Call(`_sbo_kgram_freqs_cpp`, sentences, N, dict)
}

query_kgram <- function(ptr_sexp, k, prefix, completion) {
    .Call(`_sbo_query_kgram`, ptr_sexp, k, prefix, completion)
}

query_sbo_predictor <- function(ptr_sexp, input, k) {
    .Call(`_sbo_query_sbo_predictor`, ptr_sexp, input, k)
}

#' Preprocess text corpus
#'
#' A simple text preprocessing utility.
#'
#' @export
#'
#' @author Valerio Gherardi
#' @md
#'
#' @param input a character vector.
#' @param erase a length one character vector. Regular expression matching parts of
#' text to be erased from input. The default removes anything not alphanumeric,
#' white space, apostrophes or punctuation characters (i.e. ".?!:;").
#' @param lower_case a length one logical vector. If TRUE, puts everything to lower
#' case.
#' @return a character vector containing the processed output.
#' @examples
#' preprocess("Hi @@ there! I'm using `sbo`.")
preprocess <- function(input, erase = "[^.?!:;'\\w\\s]", lower_case = TRUE) {
    .Call(`_sbo_preprocess`, input, erase, lower_case)
}

sbo_predictor_cpp <- function(freqs_ptr_sexp, lambda, L, banned) {
    .Call(`_sbo_sbo_predictor_cpp`, freqs_ptr_sexp, lambda, L, banned)
}

sbo_predictor_size <- function(preds_ptr_sexp) {
    .Call(`_sbo_sbo_predictor_size`, preds_ptr_sexp)
}

#' Sentence tokenizer
#'
#' Get sentence tokens from text
#'
#' @export
#'
#' @author Valerio Gherardi
#' @md
#'
#' @param input a character vector.
#' @param EOS a length one character vector listing all (single character)
#' end-of-sentence tokens.
#' @return a character vector, each entry of which corresponds to a single
#' sentence.
#' @examples
#' tokenize_sentences("Hi there! I'm using `sbo`.")
tokenize_sentences <- function(input, EOS = ".?!:;") {
    .Call(`_sbo_tokenize_sentences`, input, EOS)
}

